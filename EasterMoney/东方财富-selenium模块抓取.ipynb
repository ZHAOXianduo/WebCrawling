{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    " \n",
    "# 先chrome，后phantomjs\n",
    "# browser = webdriver.Chrome()\n",
    " \n",
    "# 添加无头headlesss\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "browser = webdriver.Chrome(chrome_options=chrome_options,)\n",
    " \n",
    "# browser = webdriver.PhantomJS() # 会报警高提示不建议使用phantomjs，建议chrome添加无头\n",
    "browser.maximize_window()  # 最大化窗口\n",
    "wait = WebDriverWait(browser, 10)\n",
    " \n",
    " \n",
    "def index_page(page):\n",
    "    try:\n",
    "        print('正在爬取第： %s 页' % page)\n",
    "        wait.until(\n",
    "            EC.presence_of_element_located((By.ID, \"dt_1\")))\n",
    "        # 判断是否是第1页，如果大于1就输入跳转，否则等待加载完成。\n",
    "        if page > 1:\n",
    "            # 确定页数输入框\n",
    "            input = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"PageContgopage\"]')))\n",
    "            input.click()\n",
    "            input.clear()\n",
    "            input.send_keys(page)\n",
    "            submit = wait.until(EC.element_to_be_clickable(\n",
    "                (By.CSS_SELECTOR, '#PageCont > a.btn_link')))\n",
    "            submit.click()\n",
    "            time.sleep(2)\n",
    "        # 确认成功跳转到输入框中的指定页\n",
    "        wait.until(EC.text_to_be_present_in_element(\n",
    "            (By.CSS_SELECTOR, '#PageCont > span.at'), str(page)))\n",
    "    except Exception:\n",
    "        return None\n",
    " \n",
    " \n",
    "def parse_table():\n",
    "    # 提取表格第一种方法\n",
    "    # element = wait.until(EC.presence_of_element_located((By.ID, \"dt_1\")))\n",
    "    # 第二种方法\n",
    "    element = browser.find_element_by_css_selector('#dt_1')\n",
    " \n",
    "    # 提取表格内容td\n",
    "    td_content = element.find_elements_by_tag_name(\"td\")\n",
    "    lst = []\n",
    "    for td in td_content:\n",
    "        # print(type(td.text)) # str\n",
    "        lst.append(td.text)\n",
    " \n",
    "    # 确定表格列数\n",
    "    col = len(element.find_elements_by_css_selector('tr:nth-child(1) td'))\n",
    "    # 通过定位一行td的数量，可获得表格的列数，然后将list拆分为对应列数的子list\n",
    "    lst = [lst[i:i + col] for i in range(0, len(lst), col)]\n",
    " \n",
    "    # 原网页中打开\"详细\"链接，可以查看更详细的数据，这里我们把url提取出来，方便后期查看\n",
    "    lst_link = []\n",
    "    links = element.find_elements_by_css_selector('#dt_1 a.red')\n",
    "    for link in links:\n",
    "        url = link.get_attribute('href')\n",
    "        lst_link.append(url)\n",
    " \n",
    "    lst_link = pd.Series(lst_link)\n",
    "    # list转为dataframe\n",
    "    df_table = pd.DataFrame(lst)\n",
    "    # 添加url列\n",
    "    df_table['url'] = lst_link\n",
    " \n",
    "    # print(df_table.head())\n",
    "    return df_table\n",
    " \n",
    " \n",
    "# 写入文件\n",
    "def write_to_file(df_table, category):\n",
    "    # 设置文件保存在D盘eastmoney文件夹下\n",
    "    file_path = '/Users/username/Desktop/学习'\n",
    "    if not os.path.exists(file_path):\n",
    "        os.mkdir(file_path)\n",
    "    os.chdir(file_path)\n",
    "    df_table.to_csv('{}.csv' .format(category), mode='a',\n",
    "                    encoding='utf_8_sig', index=0, header=0)\n",
    " \n",
    " \n",
    "# 设置表格获取时间、类型\n",
    "def set_table():\n",
    "    print('*' * 80)\n",
    "    print('\\t\\t\\t\\t东方财富网报表下载')\n",
    "    print('--------------')\n",
    " \n",
    "    # 1 设置财务报表获取时期\n",
    "    year = int(float(input('请输入要查询的年份(四位数2007-2018)：\\n')))\n",
    "    # int表示取整，里面加float是因为输入的是str，直接int会报错，float则不会\n",
    "    # https://stackoverflow.com/questions/1841565/valueerror-invalid-literal-for-int-with-base-10\n",
    "    while (year < 2007 or year > 2018):\n",
    "        year = int(float(input('年份数值输入错误，请重新输入：\\n')))\n",
    " \n",
    "    quarter = int(float(input('请输入小写数字季度(1:1季报，2-年中报，3：3季报，4-年报)：\\n')))\n",
    "    while (quarter < 1 or quarter > 4):\n",
    "        quarter = int(float(input('季度数值输入错误，请重新输入：\\n')))\n",
    " \n",
    "    # 转换为所需的quarter 两种方法,2表示两位数，0表示不满2位用0补充，\n",
    "    # http://www.runoob.com/python/att-string-format.html\n",
    "    quarter = '{:02d}'.format(quarter * 3)\n",
    "    # quarter = '%02d' %(int(month)*3)\n",
    "    date = '{}{}' .format(year, quarter)\n",
    "    # print(date) 测试日期 ok\n",
    " \n",
    "    # 2 设置财务报表种类\n",
    "    tables = int(\n",
    "        input('请输入查询的报表种类对应的数字(1-业绩报表；2-业绩快报表：3-业绩预告表；4-预约披露时间表；5-资产负债表；6-利润表；7-现金流量表): \\n'))\n",
    " \n",
    "    dict_tables = {1: '业绩报表', 2: '业绩快报表', 3: '业绩预告表',\n",
    "                   4: '预约披露时间表', 5: '资产负债表', 6: '利润表', 7: '现金流量表'}\n",
    "    dict = {1: 'yjbb', 2: 'yjkb/13', 3: 'yjyg',\n",
    "            4: 'yysj', 5: 'zcfz', 6: 'lrb', 7: 'xjll'}\n",
    "    category = dict[tables]\n",
    " \n",
    "    # 3 设置url\n",
    "    # url = 'http://data.eastmoney.com/bbsj/201803/lrb.html' eg.\n",
    "    url = 'http://data.eastmoney.com/{}/{}/{}.html' .format(\n",
    "        'bbsj', date, category)\n",
    " \n",
    "    # # 4 选择爬取页数范围\n",
    "    start_page = int(input('请输入下载起始页数：\\n'))\n",
    "    nums = input('请输入要下载的页数，（若需下载全部则按回车）：\\n')\n",
    "    print('*' * 80)\n",
    " \n",
    "    # 确定网页中的最后一页\n",
    "    browser.get(url)\n",
    "    # 确定最后一页页数不直接用数字而是采用定位，因为不同时间段的页码会不一样\n",
    "    try:\n",
    "        page = browser.find_element_by_css_selector('.next+ a')  # next节点后面的a节点\n",
    "    except:\n",
    "        page = browser.find_element_by_css_selector('.at+ a')\n",
    "    # else:\n",
    "    #     print('没有找到该节点')\n",
    "    # 上面用try.except是因为绝大多数页码定位可用'.next+ a'，但是业绩快报表有的只有2页，无'.next+ a'节点\n",
    "    end_page = int(page.text)\n",
    " \n",
    "    if nums.isdigit():\n",
    "        end_page = start_page + int(nums)\n",
    "    elif nums == '':\n",
    "        end_page = end_page\n",
    "    else:\n",
    "        print('页数输入错误')\n",
    " \n",
    "    # 输入准备下载表格类型\n",
    "    print('准备下载:{}-{}' .format(date, dict_tables[tables]))\n",
    "    print(url)\n",
    " \n",
    "    yield{\n",
    "        'url': url,\n",
    "        'category': dict_tables[tables],\n",
    "        'start_page': start_page,\n",
    "        'end_page': end_page\n",
    "    }\n",
    " \n",
    " \n",
    "def main(category, page):\n",
    "    try:\n",
    "        index_page(page)\n",
    "        # parse_table() #测试print\n",
    "        df_table = parse_table()\n",
    "        write_to_file(df_table, category)\n",
    "        print('第 %s 页抓取完成' % page)\n",
    "        print('--------------')\n",
    "    except Exception:\n",
    "        print('网页爬取失败，请检查网页中表格内容是否存在')\n",
    " \n",
    "# 单进程\n",
    "if __name__ == '__main__':\n",
    " \n",
    "    for i in set_table():\n",
    "        # url = i.get('url')\n",
    "        category = i.get('category')\n",
    "        start_page = i.get('start_page')\n",
    "        end_page = i.get('end_page')\n",
    " \n",
    "    for page in range(start_page, end_page):\n",
    "        # for page in range(44,pageall+1): # 如果下载中断，可以尝试手动更改网页继续下载\n",
    "        main(category, page)\n",
    "    print('全部抓取完成')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
